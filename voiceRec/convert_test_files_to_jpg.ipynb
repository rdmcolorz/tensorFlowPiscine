{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backend_bases import RendererBase\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "#import soundfile as sf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.fftpack import fft\n",
    "from scipy.misc import imresize\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import operator\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow_hub as hub\n",
    "%matplotlib inline\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_pict_path = './input/picts/newtest/'\n",
    "test_audio_path = './input/test/audio/'\n",
    "samples = []\n",
    "\n",
    "# os.system('rm -rf ./input/picts/test')\n",
    "# os.system('rm -rf ./input/picts/train')\n",
    "# os.mkdir('./input/picts/test')\n",
    "# os.mkdir('./input/picts/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, _, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wav2img(wav_path, targetdir='', figsize=(4,4)):\n",
    "    \"\"\"\n",
    "    takes in wave file path\n",
    "    and the fig size. Default 4,4 will make images 288 x 288\n",
    "    \"\"\"\n",
    "#     fig = plt.figure(figsize=figsize)\n",
    "    # use soundfile library to read in the wave files\n",
    "    samplerate, test_sound  = wavfile.read(wav_path)\n",
    "    _, spectrogram = log_specgram(test_sound, samplerate)\n",
    "    \n",
    "#     space = spectrogram.shape[0]\n",
    "#     if space < 161:\n",
    "#         spectrogram = np.pad(spectrogram, ((161-space,0), (0,0)), mode='constant', constant_values=0)\n",
    "    spectrogram = imresize(spectrogram, (28,28))\n",
    "#     spectrogram = tf.reshape(spectrogram, [-1, 161, 161, 1])\n",
    "#     spectrogram = tf.image.resize_images(spectrogram, (96, 96))\n",
    "#     spectrogram = tf.image.grayscale_to_rgb(spectrogram)\n",
    "    \n",
    "    ## create output path\n",
    "    output_file = wav_path.split('/')[-1].split('.wav')[0]\n",
    "    output_file = targetdir +'/'+ output_file\n",
    "    #plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
    "    plt.imsave('%s.jpg' % output_file, spectrogram)\n",
    "    plt.close()\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_files = [y for y in os.listdir(test_audio_path) if '.wav' in y]\n",
    "for file in all_files[95000:]:\n",
    "    wav2img(test_audio_path + file, \"./input/picts/newtest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
