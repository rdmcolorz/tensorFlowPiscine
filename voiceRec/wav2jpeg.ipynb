{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rainbowww5/anaconda3/lib/python3.5/site-packages/pydub/utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backend_bases import RendererBase\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "#import soundfile as sf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.fftpack import fft\n",
    "from scipy.misc import imresize\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import operator\n",
    "from PIL import Image\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow_hub as hub\n",
    "import time\n",
    "%matplotlib inline\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_path = './input/train/audio/'\n",
    "pict_Path = './input/picts/train/'\n",
    "test_pict_Path = './input/picts/test/'\n",
    "test_audio_path = './input/test/audio/'\n",
    "samples = []\n",
    "\n",
    "# os.system('rm -rf ./input/picts/test')\n",
    "# os.system('rm -rf ./input/picts/train')\n",
    "# os.mkdir('./input/picts/test')\n",
    "# os.mkdir('./input/picts/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subFolderList = []\n",
    "for x in os.listdir(audio_path):\n",
    "    if os.path.isdir(audio_path + '/' + x):\n",
    "        subFolderList.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def split_wav(wav_path, saved_location)\n",
    "#     myaudio = AudioSegment.from_file(wav_path, \"wav\")\n",
    "#     chunk_length_ms = 1000\n",
    "#     chunks = make_chunks(myaudio, chunk_length_ms)\n",
    "#     for i, chunk in enumerate(chunks):\n",
    "#         chunk_name = wav_path[-4:]\n",
    "#         chunk.export(chunk_name, format=\"wav\")\n",
    "        \n",
    "# wav_path = \"./input/train/audio/_background_noise_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_image(image_path, saved_location):\n",
    "    image_obj = Image.open(image_path)\n",
    "    rotated_image = image_obj.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    rotated_image.save(saved_location)\n",
    "\n",
    "    \n",
    "def rotate_image(image_path, degrees, saved_location):\n",
    "    image_obj = Image.open(image_path)\n",
    "    rotated_image = image_obj.rotate(degrees)\n",
    "    rotated_image.save(saved_location)\n",
    "\n",
    "silence = \"./input/picts/train/silence/\"\n",
    "for x in os.listdir(silence):\n",
    "    if '.jpg' in x:\n",
    "        flip_image(silence + x, silence + 'flip_' + x)\n",
    "        rotate_image(silence + x, 90, silence + 'rotate_90' + x)\n",
    "        rotate_image(silence + x, 180, silence + 'rotate_180' + x)\n",
    "        rotate_image(silence + x, 270, silence + 'rotate_270' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(pict_Path):\n",
    "    os.makedirs(pict_Path)\n",
    "\n",
    "if not os.path.exists(test_pict_Path):\n",
    "    os.makedirs(test_pict_Path)\n",
    "\n",
    "\n",
    "labels_to_keep = ['yes', 'no', 'up', 'down', 'left',\n",
    "                  'right', 'on', 'off', 'stop', 'go', 'silence', 'unknown']\n",
    "\n",
    "# for f in labels_to_keep:\n",
    "#     os.mkdir(pict_Path + f)\n",
    "    \n",
    "# for f in labels_to_keep:\n",
    "#     os.mkdir(test_pict_Path + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1733 : tree\n",
      "count: 2357 : five\n",
      "count: 1746 : dog\n",
      "count: 1742 : happy\n",
      "count: 2372 : go\n",
      "count: 2367 : right\n",
      "count: 395 : _background_noise_\n",
      "count: 1746 : marvin\n",
      "count: 2375 : no\n",
      "count: 2352 : eight\n",
      "count: 2370 : one\n",
      "count: 1713 : bed\n",
      "count: 1731 : bird\n",
      "count: 2364 : nine\n",
      "count: 1745 : wow\n",
      "count: 2373 : two\n",
      "count: 2367 : on\n",
      "count: 2380 : stop\n",
      "count: 1750 : house\n",
      "count: 2353 : left\n",
      "count: 2377 : seven\n",
      "count: 2356 : three\n",
      "count: 1734 : sheila\n",
      "count: 2376 : zero\n",
      "count: 1733 : cat\n",
      "count: 2372 : four\n",
      "count: 2357 : off\n",
      "count: 2377 : yes\n",
      "count: 2359 : down\n",
      "count: 2375 : up\n",
      "count: 2369 : six\n",
      "65116\n"
     ]
    }
   ],
   "source": [
    "sample_audio = []\n",
    "total = 0\n",
    "for x in subFolderList:\n",
    "    \n",
    "    # get all the wave files\n",
    "    all_files = [y for y in os.listdir(audio_path + x) if '.wav' in y]\n",
    "    total += len(all_files)\n",
    "    # collect the first file from each dir\n",
    "    sample_audio.append(audio_path  + x + '/'+ all_files[0])\n",
    "    \n",
    "    # show file counts\n",
    "    print('count: %d : %s' % (len(all_files), x ))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, _, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wav2img(wav_path, targetdir='', figsize=(4,4)):\n",
    "    \"\"\"\n",
    "    takes in wave file path\n",
    "    and the fig size. Default 4,4 will make images 288 x 288\n",
    "    \"\"\"\n",
    "#     fig = plt.figure(figsize=figsize)\n",
    "    # use soundfile library to read in the wave files\n",
    "    samplerate, test_sound  = wavfile.read(wav_path)\n",
    "    _, spectrogram = log_specgram(test_sound, samplerate)\n",
    "    \n",
    "    space = spectrogram.shape[0]\n",
    "    if space < 161:\n",
    "        spectrogram = np.pad(spectrogram, ((161-space,0), (0,0)), mode='constant', constant_values=0)\n",
    "    spectrogram = imresize(spectrogram, (96,96))\n",
    "#     spectrogram = tf.reshape(spectrogram, [-1, 161, 161, 1])\n",
    "#     spectrogram = tf.image.resize_images(spectrogram, (96, 96))\n",
    "#     spectrogram = tf.image.grayscale_to_rgb(spectrogram)\n",
    "    \n",
    "    ## create output path\n",
    "    output_file = wav_path.split('/')[-1].split('.wav')[0]\n",
    "    output_file = targetdir +'/'+ output_file\n",
    "    #plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
    "    plt.imsave('%s.jpg' % output_file, spectrogram)\n",
    "    plt.close()\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wav2img_waveform(wav_path, targetdir='', figsize=(4,4)):\n",
    "    samplerate,test_sound  = wavfile.read(sample_audio[0])\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.plot(test_sound)\n",
    "    plt.axis('off')\n",
    "    output_file = wav_path.split('/')[-1].split('.wav')[0]\n",
    "    output_file = targetdir +'/'+ output_file\n",
    "    plt.savefig('%s.png' % output_file)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_to_keep = ['yes', 'no', 'up', 'down', 'left',\n",
    "                  'right', 'on', 'off', 'stop', 'go']\n",
    "\n",
    "test_labels = ['yes', 'no', 'up', 'down', 'left',\n",
    "                  'right', 'on', 'off', 'stop', 'go', 'silence', 'unknown']\n",
    "\n",
    "label_dict = {'yes':0, 'no':1, 'up':2, 'down':3, 'left':4,\n",
    "                  'right':5, 'on':6, 'off':7, 'stop':8, 'go':9, 'silence':10, 'unknown':11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i, x in enumerate(['yes', 'no']):\n",
    "#         all_files = [y for y in os.listdir(audio_path + x) if '.wav' in y]\n",
    "#         for file in all_files[:]:\n",
    "#             wav2img(audio_path + x + '/' + file, './input/yes_no/' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i, x in enumerate(subFolderList):\n",
    "#     if x in labels_to_keep:\n",
    "#         print(i, ':', x)\n",
    "#         # get all the wave files\n",
    "#         all_files = [y for y in os.listdir(audio_path + x) if '.wav' in y]\n",
    "#         for file in all_files[:]:\n",
    "#             wav2img(audio_path + x + '/' + file, pict_Path + x)\n",
    "#     elif x == '_background_noise_':\n",
    "#         print(i, ':', x)\n",
    "#         # get all the wave files\n",
    "#         all_files = [y for y in os.listdir(audio_path + x) if '.wav' in y]\n",
    "#         for file in all_files[:]:\n",
    "#             wav2img(audio_path + x + '/' + file, \"./input/picts/train/silence\")\n",
    "#     else:\n",
    "#         print(i, ':', x)\n",
    "#         all_files = [y for y in os.listdir(audio_path + x) if '.wav' in y]\n",
    "#         for file in all_files[:]:\n",
    "#             wav2img(audio_path + x + '/' + file, \"./input/picts/train/unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i, x in enumerate(subFolderList):\n",
    "#     if x in labels_to_keep:\n",
    "#         print(i, ':', x)\n",
    "#         # get all the wave files\n",
    "#         all_files = [y for y in os.listdir(audio_path + x) if '.wav' in y]\n",
    "#         for file in all_files[101:120]:\n",
    "#             wav2img(audio_path + x + '/' + file, test_pict_Path + x)\n",
    "#     else:\n",
    "#         all_files = [y for y in os.listdir(audio_path + x) if '.wav' in y]\n",
    "#         for file in all_files[16:20]:\n",
    "#             wav2img(audio_path + x + '/' + file, \"./input/picts/test/unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = tf.image.decode_png(\"./input/picts/train/down/00b01445_nohash_1.png\",3)\n",
    "# sess = tf.Session()\n",
    "# print(sess.run(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11395, 96, 96, 3)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "for i, x in enumerate(test_labels): #choose the classes to train\n",
    "    all_files = [y for y in os.listdir(pict_Path + x) if '.jpg' in y]\n",
    "    for file in all_files[:1000]:\n",
    "        train_images.append(cv2.imread(pict_Path + x + '/' + file))\n",
    "        train_labels.append(label_dict[x])\n",
    "\n",
    "train_images = np.array(train_images, dtype=\"float32\")\n",
    "train_labels = np.array(train_labels)\n",
    "print(train_images.shape)\n",
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11395,)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ..., 11 11 11]\n",
      "[ 6  5 10 ...,  8  2  3]\n"
     ]
    }
   ],
   "source": [
    "train_labels.reshape((1, -1))\n",
    "train_labels = np.array(train_labels, dtype=\"int32\")\n",
    "randomize = np.arange(len(train_labels))\n",
    "np.random.shuffle(randomize)\n",
    "print(train_labels)\n",
    "labels = train_labels[randomize]\n",
    "features = train_images[randomize]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11395\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  5 10 ...,  7  4  5]\n",
      "[2 7 9 ..., 8 2 3]\n"
     ]
    }
   ],
   "source": [
    "x = len(labels)\n",
    "x *= 0.8\n",
    "x = int(x)\n",
    "training_examples = features[:x]\n",
    "validation_examples = features[x:]\n",
    "\n",
    "training_targets = labels[:x]\n",
    "validation_targets = labels[x:]\n",
    "print(training_targets)\n",
    "print(validation_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
